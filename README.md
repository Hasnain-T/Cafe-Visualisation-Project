# â˜• Cafe Sales ETL & Dashboard

A data engineering mini-project that performs **ETL (Extract, Transform, Load)** on cafÃ© sales data and automatically launches an interactive **Streamlit dashboard** for visual analysis.

---

## ğŸ“ Project Structure

- project_root/
    - â”‚
    - â”œâ”€â”€ data/
    - â”‚ â”œâ”€â”€ raw_data.csv # Input dataset (raw sales data)
    - â”‚ â””â”€â”€ cleaned_data.csv # Output dataset after ETL
    - â”‚
    - â””â”€â”€ src/
    - â”œâ”€â”€ main.py # Main ETL pipeline + dashboard launcher
    - â”œâ”€â”€ cafe_dashboard.py # Streamlit dashboard app
    - â”œâ”€â”€ extract.py # Extract data from CSV
    - â”œâ”€â”€ transform.py # Clean and transform data
    - â”œâ”€â”€ load.py # Save cleaned data to CSV
    - â”œâ”€â”€ load_to_db.py # Load data into PostgreSQL
    - â”œâ”€â”€ style.py # Custom terminal output styling

---

## ğŸš€ Features

- **Extract:** Reads raw cafÃ© sales data from a CSV file  
- **Transform:** Cleans and standardises the dataset  
- **Load:** Saves the cleaned data into a new CSV and PostgreSQL database  
- **Visualise:** Automatically launches a Streamlit dashboard with KPIs and interactive charts  

---

## ğŸ§  ETL Flow

1. **Extract** â†’ Reads `raw_data.csv`
2. **Transform** â†’ Cleans columns, formats prices, handles nulls, etc.
3. **Load** â†’ Saves cleaned data to:
   - `cleaned_data.csv`
   - PostgreSQL database (via `load_to_db.py`)
4. **Dashboard Launch** â†’ Opens `cafe_dashboard.py` in your browser

---

## ğŸ“Š Dashboard Overview

The Streamlit dashboard provides:

- ğŸ’° **Total Revenue per Drink**
- ğŸ›’ **Total Sales per Branch**
- â˜• **Average Drink Price Across Branches**
- ğŸ¬ **Branch Count**
- ğŸ“ˆ Sales Over Time
- ğŸ¥¤ Drink Popularity by Branch
- ğŸ’³ Branch vs Payment Type (Total Sales)
- ğŸ’³ Payment Type Distribution
- ğŸ’³ Payment Method Share
- ğŸŒ¡ï¸ Heatmap: Average Prices per Branch

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
- git clone https://github.com/Hasnain-T/Cafe-Visualisation-Project
- cd Cafe-Visualisation-Project


### 2ï¸âƒ£ Create and Activate a Virtual Environment
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 4ï¸âƒ£ Verify Folder Structure

Ensure src/main.py and src/cafe_dashboard.py exist, and data/raw_data.csv is available.

## ğŸ³ Docker Setup (Optional but Recommended)

You can containerize the entire ETL and database setup for consistent development.

### 1ï¸âƒ£ Install Docker & Docker Compose

- Download Docker Desktop

- Ensure Docker Engine and Compose are running.

### 2ï¸âƒ£ Example docker-compose.yml

- Check this file in your project root:
    - docker-compose.yml

### 3ï¸âƒ£ Run the containers
- docker-compose up -d

### 4ï¸âƒ£ Access Adminer

- Once running, open your browser and visit:
    - http://localhost:8080

 - Adminer login:
    - Field:	Value
    - System:	PostgreSQL
    - Server:	postgres
    - Username:	cafe_user
    - Password:	cafe_pass
    - Database:	cafe_db

## â–¶ï¸ Run the ETL Pipeline + Dashboard

- From the src directory:
    - python main.py OR py main.py OR python3 main.py


- The ETL process will extract, transform, and load your data.

- Once complete, the Streamlit dashboard will automatically launch in your browser at:
    - http://localhost:8501

### âš™ï¸ Configuration

- Update these paths in main.py if needed:
    - file_path = "../data/raw_data.csv"
    - cleaned_file_path = "../data/cleaned_data.csv"


### Database connection settings can be adjusted inside load_to_db.py.

### ğŸ§© Dependencies

- Key Python packages used:

    - pandas

    - streamlit

    - plotly

    - psycopg2

    - os, sys, subprocess

### ğŸ§¾ Example Output (Terminal)
    - [INFO] Extraction Complete.
    - [INFO] Transformation Complete.
    - [INFO] Data successfully saved to cleaned_data.csv
    - [INFO] Data successfully loaded into PostgreSQL.
    - [INFO] Launching Streamlit Dashboard...